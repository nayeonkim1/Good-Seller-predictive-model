# -*- coding: utf-8 -*-
"""goodseller_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14eML5tXVpeONPh37-tsQMkPTqy84YHzZ
"""

#나눔 폰트 설치후 런타임 재시작

!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf

import numpy as np
import pandas as pd
from google.colab import drive


drive.mount('/content/drive')

df = pd.read_excel("/content/drive/MyDrive/최종예측데이터.xlsx")
del df['Unnamed: 0']
df.head()

X = pd.DataFrame(df.iloc[:,1:-1])
y = pd.DataFrame(df['y'])

y.tail()

df['y'].value_counts()

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split


#시각화
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
from matplotlib.colors import ListedColormap
matplotlib.rcParams['axes.unicode_minus'] = False


#한글 폰트 설정
plt.rc('font', family='NanumBarunGothic')


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2022)

print(f'Train set dimension is {X_train.shape}')
print(f'Test set dimension is {X_test.shape}')

df.info()

from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
import xgboost as xgb
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier

"""## SVM """

model = svm.SVC(C=0.001,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## logistic regression

"""

model =  LogisticRegression(random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## 딥러닝"""

model = MLPClassifier(hidden_layer_sizes=(32,4),random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## XGBOOST 모형"""

model = xgb.XGBClassifier(n_estimators=100,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## GradientBoosting"""

model = GradientBoostingClassifier(n_estimators=100,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## Adaboost"""

model = AdaBoostClassifier(n_estimators=50,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## lightgbm"""

model = LGBMClassifier(n_estimators=200,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## randomforest"""

model = RandomForestClassifier(n_estimators=100,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""# resampling - SMOTE

"""

from imblearn.over_sampling import SMOTE 

sme = SMOTE(sampling_strategy=1,random_state=2022)
X, y = sme.fit_resample(X, y)

print(f'Train set dimension is {X.shape}')
print(f'Test set dimension is {y.shape}')

y['y'].value_counts()

# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2022)

"""## SVM """

model = svm.SVC(C=0.001,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## logistic regression

"""

model =  LogisticRegression(random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## 딥러닝"""

model = MLPClassifier(hidden_layer_sizes=(32,8,4),random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## XGBOOST 모형"""

model = xgb.XGBClassifier(n_estimators=100,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## GradientBoosting"""

model = GradientBoostingClassifier(n_estimators=100,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## Adaboost"""

model = AdaBoostClassifier(n_estimators=100,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

"""## lightgbm"""

model = LGBMClassifier(n_estimators=200,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))

model.fit(X,y)
feature_importances = pd.DataFrame(model.feature_importances_,
                                   index = X.columns,
                                    columns=['importance']).sort_values('importance',ascending=False)
feature_importances

"""## randomforest"""

model = RandomForestClassifier(n_estimators=100,random_state=2022)
scores = cross_val_score(model, X, y, scoring="roc_auc", cv=5, verbose=False)
# print('교차 검증별 AUC:', np.round(scores,4))
print('평균 검증 AUC:', np.round(np.mean(scores),4))